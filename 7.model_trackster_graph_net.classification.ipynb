{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c07744a",
   "metadata": {},
   "source": [
    "# Trackster-level graph net with PU\n",
    "\n",
    "Question: does including the neighborhood provide a benefit over the pairwise classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3962d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch_cluster import knn_graph\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from reco.model import DynamicEdgeConvBlock\n",
    "\n",
    "from reco.training import precision_recall_curve, roc_auc\n",
    "from reco.loss import GraphClassificationLoss\n",
    "from reco.datasetPU import TracksterGraph\n",
    "\n",
    "\n",
    "ds_name = \"CloseByTwoPion\"\n",
    "\n",
    "data_root = \"data\"\n",
    "raw_dir = f\"/Users/ecuba/data/{ds_name}\"\n",
    "\n",
    "# data_root = \"/mnt/ceph/users/ecuba/processed\"\n",
    "# raw_dir = f\"/mnt/ceph/users/ecuba/{ds_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f59304-76e4-4132-a379-978a46a042fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012b3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(data):\n",
    "    # extract the focus feature\n",
    "    data.mask = (1 - data.x[:,0]).type(torch.bool)\n",
    "    return data\n",
    "\n",
    "def knn_transform(data):\n",
    "    # pos coordinates are on position 3:6\n",
    "    data.edge_index = knn_graph(data.pos, k=4, loop=False)\n",
    "    return data\n",
    "\n",
    "def prepend_pos(data):\n",
    "    # GravNet: add S to the front\n",
    "    data.x = torch.hstack((data.pos, data.x))\n",
    "    return data\n",
    "\n",
    "transforms = T.Compose([prepend_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecf4c091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[101464, 39], y=[101464], pos=[101464, 3], e=[101464], shared_e=[101464], node_index=[101464])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TracksterGraph(\n",
    "    ds_name,\n",
    "    data_root,\n",
    "    raw_dir,\n",
    "    N_FILES=20,\n",
    "    radius=100,\n",
    "    bigT_e_th=75,\n",
    "    # transform=transforms\n",
    "    # pileup=True,\n",
    ")\n",
    "\n",
    "# ds.processed_file_names\n",
    "ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ed3e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101464"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds.data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604298f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train graphs: 2864, Test graphs: 318, total: 3182\n"
     ]
    }
   ],
   "source": [
    "ds_size = len(ds)\n",
    "test_set_size = ds_size // 10\n",
    "train_set_size = ds_size - test_set_size\n",
    "train_set, test_set = random_split(ds, [train_set_size, test_set_size])\n",
    "print(f\"Train graphs: {len(train_set)}, Test graphs: {len(test_set)}, total: {ds_size}\")\n",
    "\n",
    "train_dl = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4a0b99-bef3-4c82-a0ac-d88e1521382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracksterGraphNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, dropout=0.2, S=3):\n",
    "        super(TracksterGraphNet, self).__init__()\n",
    "        \n",
    "        hdim1 = 64\n",
    "        hdim2 = 64\n",
    "        hdim3 = 64\n",
    "\n",
    "        hdim_fc = 256\n",
    "\n",
    "        self.edgeconv1 = DynamicEdgeConvBlock(input_dim, hdim1)\n",
    "        self.edgeconv2 = DynamicEdgeConvBlock(hdim1, hdim2)\n",
    "        self.edgeconv3 = DynamicEdgeConvBlock(hdim2, hdim3)\n",
    "        \n",
    "        # Edge features from node embeddings for classification        \n",
    "        self.nodenetwork = nn.Sequential(\n",
    "            nn.Linear(hdim3, hdim_fc),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hdim_fc, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        H1 = self.edgeconv1(X)\n",
    "        H2 = self.edgeconv2(H1)\n",
    "        H3 = self.edgeconv3(H2)\n",
    "        return self.nodenetwork(H3).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce36485",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TracksterGraphNet(input_dim=ds.data.x.shape[1])\n",
    "epochs = 10\n",
    "model_path = f\"models/TracksterGraphNet.DGCNN.ns.{epochs}e-{ds_name}.r{ds.RADIUS}.e{ds.bigT_e_th}.f{ds.N_FILES}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2539cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph_classification(model, device, optimizer, loss_func, train_dl):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for data in train_dl:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        seg_pred = model(data.x)\n",
    "        loss = loss_func(data, seg_pred)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259ee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_graph_classification(model, device, loss_func, test_dl):\n",
    "    test_loss = []\n",
    "    model.eval()\n",
    "    for data in test_dl:\n",
    "        data = data.to(device)\n",
    "        seg_pred = model(data.x)\n",
    "        loss = loss_func(data, seg_pred)\n",
    "        test_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d3f1e82-74c5-4629-9b20-f05d7662aaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "# alpha - percentage of negative edges\n",
    "loss_func = GraphClassificationLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=1e-5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss = train_graph_classification(\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        loss_func,\n",
    "        train_dl\n",
    "    )\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        test_loss = test_graph_classification(model, device, loss_func, test_dl)\n",
    "        print(\n",
    "            f\"Epoch {epoch}\\t train loss: {train_loss:.3f}\\t test loss: {test_loss:.3f}\",\n",
    "            file=sys.stderr\n",
    "        )\n",
    "        \n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9cbaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script echo skipping\n",
    "model.load_state_dict(torch.load(\n",
    "    model_path,\n",
    "    map_location=device\n",
    "))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86c98db-0ac0-4a0c-84fd-4c50df507528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "print(roc_auc(model, device, test_dl))\n",
    "precision_recall_curve(model, device, test_dl, focus_metric=\"fbeta\", beta=0.5, step=3, truth_threshold=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb8ce4e2",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3f12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from reco.data import get_event_data\n",
    "from reco.evaluation import model_evaluation\n",
    "\n",
    "# from reco.dummy import DummyPleaser\n",
    "\n",
    "file_name = f\"{raw_dir}/new_ntuples_15101852_0.root\"\n",
    "cluster_data, trackster_data, simtrackster_data, assoc_data = get_event_data(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5ffc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event 0:\n",
      "\tclue3d_to_sim:\tP: 0.988 R: 0.229 F: 0.594\n",
      "\ttarget_to_sim:\tP: 0.981 R: 0.686 F: 0.903\n",
      "\treco_to_sim:\tP: 0.974 R: 0.678 F: 0.896\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 1:\n",
      "\tNo data\n",
      "Event 2:\n",
      "\tclue3d_to_sim:\tP: 1.000 R: 0.396 F: 0.766\n",
      "\ttarget_to_sim:\tP: 0.999 R: 0.814 F: 0.956\n",
      "\treco_to_sim:\tP: 0.973 R: 0.795 F: 0.931\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 3:\n",
      "\tclue3d_to_sim:\tP: 0.995 R: 0.383 F: 0.754\n",
      "\ttarget_to_sim:\tP: 0.991 R: 0.782 F: 0.941\n",
      "\treco_to_sim:\tP: 0.979 R: 0.767 F: 0.928\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 4:\n",
      "\tclue3d_to_sim:\tP: 0.998 R: 0.250 F: 0.625\n",
      "\ttarget_to_sim:\tP: 0.996 R: 0.838 F: 0.960\n",
      "\treco_to_sim:\tP: 0.987 R: 0.828 F: 0.951\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 5:\n",
      "\tclue3d_to_sim:\tP: 0.996 R: 0.551 F: 0.858\n",
      "\ttarget_to_sim:\tP: 0.995 R: 0.839 F: 0.959\n",
      "\treco_to_sim:\tP: 0.963 R: 0.804 F: 0.926\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 6:\n",
      "\tclue3d_to_sim:\tP: 0.992 R: 0.219 F: 0.582\n",
      "\ttarget_to_sim:\tP: 0.992 R: 0.727 F: 0.925\n",
      "\treco_to_sim:\tP: 0.941 R: 0.668 F: 0.870\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 7:\n",
      "\tNo data\n",
      "Event 8:\n",
      "\tclue3d_to_sim:\tP: 0.997 R: 0.413 F: 0.777\n",
      "\ttarget_to_sim:\tP: 0.996 R: 0.761 F: 0.938\n",
      "\treco_to_sim:\tP: 0.996 R: 0.761 F: 0.938\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 9:\n",
      "\tclue3d_to_sim:\tP: 0.998 R: 0.177 F: 0.518\n",
      "\ttarget_to_sim:\tP: 0.998 R: 0.559 F: 0.862\n",
      "\treco_to_sim:\tP: 0.975 R: 0.535 F: 0.837\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 10:\n",
      "\tNo data\n",
      "Event 11:\n",
      "\tclue3d_to_sim:\tP: 0.999 R: 0.524 F: 0.846\n",
      "\ttarget_to_sim:\tP: 0.999 R: 0.829 F: 0.960\n",
      "\treco_to_sim:\tP: 0.999 R: 0.829 F: 0.960\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 12:\n",
      "\tclue3d_to_sim:\tP: 0.984 R: 0.277 F: 0.651\n",
      "\ttarget_to_sim:\tP: 0.975 R: 0.616 F: 0.873\n",
      "\treco_to_sim:\tP: 0.955 R: 0.595 F: 0.852\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 13:\n",
      "\tclue3d_to_sim:\tP: 1.000 R: 0.258 F: 0.635\n",
      "\ttarget_to_sim:\tP: 1.000 R: 0.757 F: 0.939\n",
      "\treco_to_sim:\tP: 0.952 R: 0.691 F: 0.885\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 14:\n",
      "\tclue3d_to_sim:\tP: 0.976 R: 0.155 F: 0.475\n",
      "\ttarget_to_sim:\tP: 0.970 R: 0.598 F: 0.863\n",
      "\treco_to_sim:\tP: 0.955 R: 0.561 F: 0.837\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 15:\n",
      "\tclue3d_to_sim:\tP: 0.996 R: 0.209 F: 0.568\n",
      "\ttarget_to_sim:\tP: 0.993 R: 0.758 F: 0.935\n",
      "\treco_to_sim:\tP: 0.955 R: 0.715 F: 0.895\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 16:\n",
      "\tNo data\n",
      "Event 17:\n",
      "\tclue3d_to_sim:\tP: 0.985 R: 0.268 F: 0.642\n",
      "\ttarget_to_sim:\tP: 0.981 R: 0.763 F: 0.928\n",
      "\treco_to_sim:\tP: 0.958 R: 0.691 F: 0.889\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 18:\n",
      "\tclue3d_to_sim:\tP: 0.989 R: 0.317 F: 0.695\n",
      "\ttarget_to_sim:\tP: 0.985 R: 0.801 F: 0.942\n",
      "\treco_to_sim:\tP: 0.962 R: 0.787 F: 0.921\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "Event 19:\n",
      "\tclue3d_to_sim:\tP: 0.991 R: 0.277 F: 0.654\n",
      "\ttarget_to_sim:\tP: 0.987 R: 0.494 F: 0.823\n",
      "\treco_to_sim:\tP: 0.956 R: 0.454 F: 0.783\n",
      "\t|S| = 2 |T| = 2 |R| = 2\n",
      "-----\n",
      "mean clue3d_to_sim:\tP: 0.993 R: 0.307 F: 0.665\n",
      "mean target_to_sim:\tP: 0.990 R: 0.726 F: 0.919\n",
      "mean reco_to_sim:\tP: 0.968 R: 0.698 F: 0.894\n"
     ]
    }
   ],
   "source": [
    "result = model_evaluation(\n",
    "    cluster_data,\n",
    "    trackster_data,\n",
    "    simtrackster_data,\n",
    "    assoc_data,\n",
    "    model,\n",
    "    decision_th=0.5,\n",
    "    radius=100,\n",
    "    max_events=20,\n",
    "    bigT_e_th=75,\n",
    "    graph=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328866f1-c862-4dfb-a201-91d2baa53d9f",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Using alpha=balance seems to converge faster (100 epochs rather than 200)\n",
    "- maybe just sticking to 0.25? (works just fine)\n",
    "\n",
    "Hyperparams\n",
    "- (64, 128, noskip), alpha=balance, roc_auc = 0.9733\n",
    "- (64, 128, 256fc, noskip, 200e), alpha=1-balance, roc_auc = 0.9771\n",
    "- (64, 128, 256fc, noskip, 200e), alpha=balance, roc_auc = 0.981\n",
    "- (64, 128, 256fc, noskip, 100e), alpha=0.25, roc_auc = 0.9796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69420f64-42b0-4a8b-b4dc-d88ae1242f51",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperatorError",
     "evalue": "ONNX export failed on an operator with unrecognized namespace torch_cluster::knn. If you are trying to export a custom operator, make sure you registered it with the right domain and version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m\n\u001b[1;32m      3\u001b[0m onnx_filepath \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monnx/TracksterGraphNet.mask.64.128.256.ns.\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39me-\u001b[39m\u001b[39m{\u001b[39;00mds_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mds\u001b[39m.\u001b[39mRADIUS\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mds\u001b[39m.\u001b[39mSCORE_THRESHOLD\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mds\u001b[39m.\u001b[39mN_FILES\u001b[39m}\u001b[39;00m\u001b[39mf.onnx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(\n\u001b[1;32m      6\u001b[0m     model,                          \u001b[39m# model to be exported\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m     (ds[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mx),    \u001b[39m# example input (add batch dimension)\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m     onnx_filepath,\n\u001b[1;32m      9\u001b[0m     export_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     10\u001b[0m     opset_version\u001b[39m=\u001b[39;49m\u001b[39m11\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     do_constant_folding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     12\u001b[0m     input_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m'\u001b[39;49m],      \u001b[39m# the model's input names\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m     output_names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m'\u001b[39;49m],    \u001b[39m# the model's output names\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49m{              \u001b[39m# variable length axes\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m'\u001b[39;49m : {\u001b[39m0\u001b[39;49m : \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m},    \n\u001b[1;32m     16\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m'\u001b[39;49m : {\u001b[39m0\u001b[39;49m : \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m}\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     18\u001b[0m )\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/onnx/__init__.py:350\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mExports a model into ONNX format. If ``model`` is not a\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m:class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m    model to the file ``f`` even if this is raised.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m--> 350\u001b[0m \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39;49mexport(\n\u001b[1;32m    351\u001b[0m     model,\n\u001b[1;32m    352\u001b[0m     args,\n\u001b[1;32m    353\u001b[0m     f,\n\u001b[1;32m    354\u001b[0m     export_params,\n\u001b[1;32m    355\u001b[0m     verbose,\n\u001b[1;32m    356\u001b[0m     training,\n\u001b[1;32m    357\u001b[0m     input_names,\n\u001b[1;32m    358\u001b[0m     output_names,\n\u001b[1;32m    359\u001b[0m     operator_export_type,\n\u001b[1;32m    360\u001b[0m     opset_version,\n\u001b[1;32m    361\u001b[0m     do_constant_folding,\n\u001b[1;32m    362\u001b[0m     dynamic_axes,\n\u001b[1;32m    363\u001b[0m     keep_initializers_as_inputs,\n\u001b[1;32m    364\u001b[0m     custom_opsets,\n\u001b[1;32m    365\u001b[0m     export_modules_as_functions,\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/onnx/utils.py:163\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    146\u001b[0m     model,\n\u001b[1;32m    147\u001b[0m     args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m     export_modules_as_functions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m ):\n\u001b[0;32m--> 163\u001b[0m     _export(\n\u001b[1;32m    164\u001b[0m         model,\n\u001b[1;32m    165\u001b[0m         args,\n\u001b[1;32m    166\u001b[0m         f,\n\u001b[1;32m    167\u001b[0m         export_params,\n\u001b[1;32m    168\u001b[0m         verbose,\n\u001b[1;32m    169\u001b[0m         training,\n\u001b[1;32m    170\u001b[0m         input_names,\n\u001b[1;32m    171\u001b[0m         output_names,\n\u001b[1;32m    172\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    173\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    174\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    175\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    176\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    177\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    178\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    179\u001b[0m     )\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/onnx/utils.py:1074\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1072\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1074\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1075\u001b[0m     model,\n\u001b[1;32m   1076\u001b[0m     args,\n\u001b[1;32m   1077\u001b[0m     verbose,\n\u001b[1;32m   1078\u001b[0m     input_names,\n\u001b[1;32m   1079\u001b[0m     output_names,\n\u001b[1;32m   1080\u001b[0m     operator_export_type,\n\u001b[1;32m   1081\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1082\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1083\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1084\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1085\u001b[0m )\n\u001b[1;32m   1087\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1089\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1090\u001b[0m )\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/onnx/utils.py:731\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    728\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m    730\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 731\u001b[0m     graph \u001b[39m=\u001b[39m _optimize_graph(\n\u001b[1;32m    732\u001b[0m         graph,\n\u001b[1;32m    733\u001b[0m         operator_export_type,\n\u001b[1;32m    734\u001b[0m         _disable_torch_constant_prop\u001b[39m=\u001b[39;49m_disable_torch_constant_prop,\n\u001b[1;32m    735\u001b[0m         fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m    736\u001b[0m         params_dict\u001b[39m=\u001b[39;49mparams_dict,\n\u001b[1;32m    737\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    738\u001b[0m         input_names\u001b[39m=\u001b[39;49minput_names,\n\u001b[1;32m    739\u001b[0m         module\u001b[39m=\u001b[39;49mmodule,\n\u001b[1;32m    740\u001b[0m     )\n\u001b[1;32m    741\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    742\u001b[0m     torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mTorch IR graph at exception: \u001b[39m\u001b[39m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/onnx/utils.py:308\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    306\u001b[0m     _C\u001b[39m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    307\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 308\u001b[0m graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39;49m_jit_pass_onnx(graph, operator_export_type)\n\u001b[1;32m    309\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    310\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/onnx/__init__.py:416\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_symbolic_function\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    414\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monnx\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m--> 416\u001b[0m     \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39;49m_run_symbolic_function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/onnx/utils.py:1421\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(g, block, n, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[39mreturn\u001b[39;00m g\u001b[39m.\u001b[39mat(  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m             op_name, \u001b[39m*\u001b[39minputs, overload_name\u001b[39m=\u001b[39m_get_aten_op_overload_name(n), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattrs\n\u001b[1;32m   1419\u001b[0m         )\n\u001b[1;32m   1420\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1421\u001b[0m         \u001b[39mraise\u001b[39;00m symbolic_registry\u001b[39m.\u001b[39mUnsupportedOperatorError(\n\u001b[1;32m   1422\u001b[0m             domain, op_name, opset_version\n\u001b[1;32m   1423\u001b[0m         )\n\u001b[1;32m   1424\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m     \u001b[39mif\u001b[39;00m operator_export_type \u001b[39m==\u001b[39m _C_onnx\u001b[39m.\u001b[39mOperatorExportTypes\u001b[39m.\u001b[39mONNX_FALLTHROUGH:\n",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m: ONNX export failed on an operator with unrecognized namespace torch_cluster::knn. If you are trying to export a custom operator, make sure you registered it with the right domain and version."
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "onnx_filepath = f\"onnx/TracksterGraphNet.mask.64.128.256.ns.{epochs}e-{ds_name}.{ds.RADIUS}.{ds.SCORE_THRESHOLD}.{ds.N_FILES}f.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                          # model to be exported\n",
    "    (ds[0].x),    # example input (add batch dimension)\n",
    "    onnx_filepath,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['features'],      # the model's input names\n",
    "    output_names=['output'],    # the model's output names\n",
    "    dynamic_axes={              # variable length axes\n",
    "        'features' : {0 : 'batch_size'},    \n",
    "        'output' : {0 : 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1c5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ve': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "37c238d9819f69c2c770157eac01081978c120e64661e10d7fd52c4caf977dc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
