{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c07744a",
   "metadata": {},
   "source": [
    "# Pairwise MLP approach\n",
    "\n",
    "Get tracksters from a certain neighbourhood.\n",
    "\n",
    "Train a NN to decide whether two tracksters should be joined.\n",
    "\n",
    "Neighbourhood:\n",
    "- get links from ticlNtuplizer/graph\n",
    "    - figure out how these links are formed\n",
    "- convert the tracksters into some latent space and predict a link between them\n",
    "- later extend this using edgeconv or sageconf to add information from the neighbourhood\n",
    "\n",
    "Graph:\n",
    "- linked_inners\n",
    "    - nodes linked to the given tracksters within its cone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3247338",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ffdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from reco.data_utils import TracksterPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7af3ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Apple silicon setup\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2dc29a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = \"cpu\"    # torch mps implementation sucks\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "219c077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  80.8828, -108.8683,  380.0638,   60.2691,   75.7790, -109.8341,\n",
       "          337.5883,  353.5663]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TracksterPairs(\"data\", N_FILES=5)\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10f015a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.x = torch.nn.functional.normalize(ds.x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84179ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0099, -0.0140,  0.0093,  0.0140,  0.0097, -0.0147,  0.0086,  0.0460])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27159145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairWiseMLP(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden=10):\n",
    "        super(PairWiseMLP, self).__init__()\n",
    "\n",
    "        self.W1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.W2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.W3 = nn.Linear(num_hidden, 1)\n",
    "        self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.W1(data)\n",
    "        x = self.activation(x)\n",
    "        x = self.W2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.W3(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d3700ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = torch.nn.BCELoss()\n",
    "\n",
    "def train(model, opt, loader):\n",
    "    epoch_loss = 0\n",
    "    for batch, labels in loader:\n",
    "        model.train()\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        opt.zero_grad()\n",
    "        z = model(batch).reshape(-1)\n",
    "        loss = loss_obj(z, labels)\n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return float(epoch_loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch, labels in data:\n",
    "        model.eval()\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        z = model(batch).reshape(-1)\n",
    "        prediction = (z > 0.5).type(torch.int)\n",
    "        total += len(prediction) \n",
    "        correct += sum(prediction == labels.type(torch.int))\n",
    "    return (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1e8002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 9470, Test samples: 1052\n"
     ]
    }
   ],
   "source": [
    "ds_size = len(ds)\n",
    "test_set_size = ds_size // 10\n",
    "train_set_size = ds_size - test_set_size\n",
    "train_set, test_set = random_split(ds, [train_set_size, test_set_size])\n",
    "print(f\"Train samples: {len(train_set)}, Test samples: {len(test_set)}\")\n",
    "\n",
    "train_dl = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1bdabc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial acc: 0.5048\n",
      "Epoch: 10, loss: 219.9350, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 20, loss: 229.2296, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 30, loss: 231.3980, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 40, loss: 230.3350, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 50, loss: 234.3919, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 60, loss: 219.2107, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 70, loss: 220.5267, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 80, loss: 216.2666, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 90, loss: 217.2358, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 100, loss: 213.6661, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 110, loss: 214.4244, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 120, loss: 212.5400, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 130, loss: 212.4735, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 140, loss: 214.9870, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 150, loss: 210.6201, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 160, loss: 208.4183, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 170, loss: 208.3025, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 180, loss: 209.4165, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 190, loss: 208.2344, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 200, loss: 209.8110, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 210, loss: 206.8762, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 220, loss: 208.0784, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 230, loss: 208.0041, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 240, loss: 207.1057, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 250, loss: 207.7151, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 260, loss: 206.0326, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 270, loss: 205.9555, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 280, loss: 206.1439, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 290, loss: 206.6392, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 300, loss: 206.3284, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 310, loss: 205.7208, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 320, loss: 205.6472, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 330, loss: 205.7137, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 340, loss: 205.7814, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 350, loss: 205.8194, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 360, loss: 205.4692, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 370, loss: 205.3843, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 380, loss: 205.4424, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 390, loss: 205.6064, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 400, loss: 205.3988, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 410, loss: 205.3485, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 420, loss: 205.4333, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 430, loss: 205.3359, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 440, loss: 205.3230, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 450, loss: 205.3708, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 460, loss: 205.2242, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 470, loss: 205.2627, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 480, loss: 205.2312, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 490, loss: 205.2671, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 500, loss: 205.2747, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 510, loss: 205.2343, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 520, loss: 205.2118, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 530, loss: 205.2387, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 540, loss: 205.2209, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 550, loss: 205.2349, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 560, loss: 205.1962, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 570, loss: 205.1854, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 580, loss: 205.1974, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 590, loss: 205.2020, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 600, loss: 205.1874, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 610, loss: 205.1881, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 620, loss: 205.1832, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 630, loss: 205.1854, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 640, loss: 205.1824, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 650, loss: 205.1970, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 660, loss: 205.1780, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 670, loss: 205.1825, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 680, loss: 205.1800, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 690, loss: 205.1793, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 700, loss: 205.1802, train acc: 0.4995, test acc: 0.5048\n",
      "Epoch: 710, loss: 205.1745, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 720, loss: 205.1750, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 730, loss: 205.1781, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 740, loss: 205.1763, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 750, loss: 205.1760, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 760, loss: 205.1740, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 770, loss: 205.1729, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 780, loss: 205.1741, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 790, loss: 205.1737, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 800, loss: 205.1738, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 810, loss: 205.1723, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 820, loss: 205.1724, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 830, loss: 205.1723, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 840, loss: 205.1725, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 850, loss: 205.1726, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 860, loss: 205.1721, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 870, loss: 205.1720, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 880, loss: 205.1719, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 890, loss: 205.1719, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 900, loss: 205.1721, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 910, loss: 205.1718, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 920, loss: 205.1716, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 930, loss: 205.1717, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 940, loss: 205.1716, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 950, loss: 205.1715, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 960, loss: 205.1714, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 970, loss: 205.1716, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 980, loss: 205.1714, train acc: 0.5005, test acc: 0.4952\n",
      "Epoch: 990, loss: 205.1716, train acc: 0.5005, test acc: 0.4952\n"
     ]
    }
   ],
   "source": [
    "model = PairWiseMLP(ds.x.shape[1], 128)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "test_acc = test(model, test_dl)\n",
    "print(f\"Initial acc: {test_acc:.4f}\")\n",
    "\n",
    "for epoch in range(1, 1000):\n",
    "    loss = train(model, optimizer, train_dl)\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = test(model, train_dl)\n",
    "        test_acc = test(model, test_dl)\n",
    "        print(f'Epoch: {epoch}, loss: {loss:.4f}, train acc: {train_acc:.4f}, test acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849a1318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 44, TN: 81, FP: 31, FN: 68\n",
      "Accuracy: 0.5580\n",
      "Precision: 0.5867\n",
      "Recall: 0.3929\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "lab = []\n",
    "for b in test_dl:\n",
    "    pred += (model(b) > 0.5).type(torch.int).tolist()\n",
    "    lab += b.y.tolist()\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(lab, pred).ravel()\n",
    "print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
    "print(f'Accuracy: {accuracy_score(lab, pred):.4f}')\n",
    "print(f'Precision: {precision_score(lab, pred):.4f}')\n",
    "print(f'Recall: {recall_score(lab, pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877b173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('ve': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "75d0e37245d408f3d59eb152d126431f02f862b5012558b3df6d65a37ffc466c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
