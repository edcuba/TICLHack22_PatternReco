{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fe0868",
   "metadata": {},
   "source": [
    "# Object condensation using CLUE3D\n",
    "\n",
    "Goal:\n",
    "- start with layer-clusters (x,y,z,e)\n",
    "- run edgeconv\n",
    "- collapse to tracksters\n",
    "- run edgeconv\n",
    "- fully connected\n",
    "- query edges\n",
    "- output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0daf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.utils as geo_utils\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from reco.model import EdgeConvNet\n",
    "from torch_geometric.nn import EdgeConv, DynamicEdgeConv, global_mean_pool\n",
    "\n",
    "from reco.learn import train_edge_pred, test_edge_pred\n",
    "from reco.dataset import PointCloudSet\n",
    "from reco.loss import FocalLoss\n",
    "from reco.training import split_geo_train_test\n",
    "\n",
    "data_root = \"data\"\n",
    "ds_name = \"MultiParticle\"\n",
    "raw_dir = f\"/Users/ecuba/data/{ds_name}\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc82d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive edge ratio: 0.362\n",
      "Train set: 4500, Test set: 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[10684122, 4], edge_index=[2, 2695051], y=[2695051], trackster_index=[10684122])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = T.Compose([T.NormalizeFeatures()])\n",
    "\n",
    "ds = PointCloudSet(\n",
    "    ds_name,\n",
    "    data_root,\n",
    "    raw_dir,\n",
    "    transform=transform, # todo: z-axis transformation\n",
    "    N_FILES=50,\n",
    ")\n",
    "\n",
    "positive_edge_fr = float(sum(ds.data.y) / len(ds.data.y))\n",
    "print(f\"Positive edge ratio: {positive_edge_fr:.3f}\") \n",
    "train_dl, test_dl = split_geo_train_test(ds, batch_size=1)\n",
    "ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161f1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudNet(nn.Module):\n",
    "    def __init__(self, input_dim=4, output_dim=1, aggr='add', dropout=0.2):\n",
    "        super(PointCloudNet, self).__init__()\n",
    "\n",
    "        lc_hdim1 = 32        \n",
    "        lc_hdim2 = 64\n",
    "\n",
    "        tr_hdim1 = 64\n",
    "        tr_hdim2 = 64\n",
    "\n",
    "        fc_hdim = 128\n",
    "\n",
    "        k=4\n",
    "\n",
    "        # EdgeConv on LC\n",
    "        self.lc_conv1 = DynamicEdgeConv(nn=EdgeConvNet(input_dim, lc_hdim1), aggr=aggr, k=k)\n",
    "        self.lc_conv2 = DynamicEdgeConv(nn=EdgeConvNet(lc_hdim1, lc_hdim2), aggr=aggr, k=k)\n",
    "\n",
    "        # EdgeConv on Tracksters\n",
    "        self.trackster_conv1 = DynamicEdgeConv(nn=EdgeConvNet(lc_hdim2, tr_hdim1), aggr=aggr, k=k)\n",
    "        self.trackster_conv2 = DynamicEdgeConv(nn=EdgeConvNet(tr_hdim1, tr_hdim2), aggr=aggr, k=k)\n",
    "\n",
    "        # Edge features from node embeddings for classification\n",
    "        self.edgenetwork = nn.Sequential(\n",
    "            nn.Linear(2 * tr_hdim2, fc_hdim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fc_hdim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "    def forward(self, X, query, tr_index):        \n",
    "\n",
    "        # tr index has gaps due to wrong reindexation on pytorch geometric with batch_size > 1\n",
    "        # last = -1\n",
    "        # idx = -1\n",
    "        # tridx2lc = {}\n",
    "        # l_tr_index = tr_index.tolist()\n",
    "        # new_idx = [0] * len(l_tr_index)\n",
    "        # for i, tr_i in enumerate(l_tr_index):\n",
    "        #     if tr_i != last:\n",
    "        #         last = tr_i\n",
    "        #         idx += 1\n",
    "        #         tridx2lc[idx] = []\n",
    "\n",
    "        #     new_idx[i] = idx\n",
    "        #     tridx2lc[idx].append(i)\n",
    "\n",
    "        # build knn edges within each trackster\n",
    "        # lc_edges = []   # knn edges witin a trackster\n",
    "\n",
    "        # Convolution on layer-clusters\n",
    "        H = self.lc_conv1(X)    # (BATCH_SIZE, N_LC, 4) -> (BATCH_SIZE, N_LC, 32)\n",
    "        H = self.lc_conv2(H)    # (BATCH_SIZE, N_LC, 32) -> (BATCH_SIZE, N_LC, 64)\n",
    "\n",
    "        # Condensation into tracksters using pooling: (max, mean, add, topK, self-attention)\n",
    "        TX = global_mean_pool(H, tr_index)  # (BATCH_SIZE, N_LC, 64) -> (BATCH_SIZE, N_TR, 64)\n",
    "\n",
    "        # Convolution on tracksters\n",
    "        H = self.trackster_conv1(TX)    # (BATCH_SIZE, N_TR, 64) -> (BATCH_SIZE, N_TR, 64)\n",
    "        H = self.trackster_conv2(H)     # (BATCH_SIZE, N_TR, 64) -> (BATCH_SIZE, N_TR, 64)\n",
    "\n",
    "        src, dst = query\n",
    "        q_edges = torch.cat([H[src], H[dst]], dim=-1)   # (BATCH_SIZE, N_TR, 64) -> (BATCH_SIZE, Q_EDGES, 128)\n",
    "        return self.edgenetwork(q_edges).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "596358f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \ttrain loss:339.83\ttrain acc: 0.655 \t test loss:702.53 \t test acc: 0.382\n",
      "Epoch 1: \ttrain loss:318.41\ttrain acc: 0.668 \t test loss:577.36 \t test acc: 0.398\n",
      "Epoch 2: \ttrain loss:307.33\ttrain acc: 0.674 \t test loss:671.88 \t test acc: 0.405\n",
      "Epoch 3: \ttrain loss:299.45\ttrain acc: 0.679 \t test loss:1542.02 \t test acc: 0.403\n",
      "Epoch 4: \ttrain loss:292.91\ttrain acc: 0.683 \t test loss:1039.65 \t test acc: 0.404\n",
      "Epoch 5: \ttrain loss:287.49\ttrain acc: 0.687 \t test loss:1988.55 \t test acc: 0.405\n",
      "Epoch 6: \ttrain loss:283.05\ttrain acc: 0.690 \t test loss:2640.19 \t test acc: 0.404\n",
      "Epoch 7: \ttrain loss:279.06\ttrain acc: 0.693 \t test loss:3652.29 \t test acc: 0.395\n",
      "Epoch 8: \ttrain loss:275.50\ttrain acc: 0.696 \t test loss:4190.82 \t test acc: 0.390\n",
      "Epoch 9: \ttrain loss:272.45\ttrain acc: 0.698 \t test loss:3704.50 \t test acc: 0.394\n"
     ]
    }
   ],
   "source": [
    "model = PointCloudNet(input_dim=ds.data.x.shape[1])\n",
    "epochs = 10\n",
    "\n",
    "# loss_func = F.binary_cross_entropy_with_logits\n",
    "# alpha - percentage of negative edges\n",
    "loss_func = FocalLoss(alpha=positive_edge_fr, gamma=2)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_true, train_pred = train_edge_pred(\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        loss_func,\n",
    "        train_dl\n",
    "    )\n",
    "    \n",
    "    train_acc = metrics.accuracy_score(train_true, (train_pred > 0.5).astype(int))\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        test_loss, test_true, test_pred = test_edge_pred(model, device, loss_func, test_dl)\n",
    "        test_acc = metrics.accuracy_score(test_true, (test_pred > 0.5).astype(int))\n",
    "        print(\n",
    "            f\"Epoch {epoch}:\",\n",
    "            f\"\\ttrain loss:{train_loss:.2f}\\ttrain acc: {train_acc:.3f}\",\n",
    "            f\"\\t test loss:{test_loss:.2f} \\t test acc: {test_acc:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd448a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "75d0e37245d408f3d59eb152d126431f02f862b5012558b3df6d65a37ffc466c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
