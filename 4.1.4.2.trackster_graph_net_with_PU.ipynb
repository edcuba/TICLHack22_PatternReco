{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c07744a",
   "metadata": {},
   "source": [
    "# Trackster-level graph net with PU\n",
    "\n",
    "Question: does including the neughbourhood provide benefir over pairwise classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3962d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.nn import DynamicEdgeConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from reco.training import train_edge_pred, test_edge_pred, precision_recall_curve\n",
    "from reco.loss import FocalLoss\n",
    "from reco.datasetPU import TracksterGraphPU\n",
    "\n",
    "\n",
    "# ds_name = \"CloseByGamma200PUFull\"\n",
    "# data_root = \"data\"\n",
    "# raw_dir = f\"/Users/ecuba/data/{ds_name}\"\n",
    "\n",
    "data_root = \"/mnt/ceph/users/ecuba/processed\"\n",
    "ds_name = \"CloseByGamma200PUFull\"\n",
    "raw_dir = f\"/mnt/ceph/users/ecuba/{ds_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f59304-76e4-4132-a379-978a46a042fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecf4c091",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m transform \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose([T\u001b[38;5;241m.\u001b[39mNormalizeScale()])\n\u001b[0;32m----> 3\u001b[0m ds \u001b[38;5;241m=\u001b[39m TracksterGraphPU(\n\u001b[1;32m      4\u001b[0m     ds_name,\n\u001b[1;32m      5\u001b[0m     data_root,\n\u001b[1;32m      6\u001b[0m     raw_dir,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# transform=transform,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     N_FILES\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m     radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m ds\u001b[38;5;241m.\u001b[39mprocessed_file_names\n",
      "File \u001b[0;32m~/TICLPatternReco/reco/datasetPU.py:287\u001b[0m, in \u001b[0;36mTracksterGraphPU.__init__\u001b[0;34m(self, name, root_dir, raw_data_path, transform, pre_transform, pre_filter, N_FILES, radius, score_threshold)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRADIUS \u001b[38;5;241m=\u001b[39m radius\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSCORE_THRESHOLD \u001b[38;5;241m=\u001b[39m score_threshold\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTracksterGraphPU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root_dir, transform, pre_transform, pre_filter)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([T.NormalizeScale()])\n",
    "\n",
    "ds = TracksterGraphPU(\n",
    "    ds_name,\n",
    "    data_root,\n",
    "    raw_dir,\n",
    "    # transform=transform,\n",
    "    N_FILES=1,\n",
    "    radius=10,\n",
    ")\n",
    "\n",
    "ds.processed_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604298f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = len(ds)\n",
    "test_set_size = ds_size // 10\n",
    "train_set_size = ds_size - test_set_size\n",
    "train_set, test_set = random_split(ds, [train_set_size, test_set_size])\n",
    "print(f\"Train graphs: {len(train_set)}, Test graphs: {len(test_set)}\")\n",
    "\n",
    "train_dl = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f24ba-0c3c-4793-ab31-e2b699e69a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels (one per layer-cluster):\", len(ds.data.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c217aff-c1a6-4fa9-9f17-2a03f9aa93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = float(sum(ds.data.y) / len(ds.data.y))\n",
    "print(f\"dataset balance: {balance:.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a0b99-bef3-4c82-a0ac-d88e1521382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, aggr=\"add\", skip_link=False, k=8):\n",
    "        super(EdgeConvBlock, self).__init__()\n",
    "\n",
    "        convnetwork = nn.Sequential(\n",
    "            nn.Linear(2 * input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.dynamicgraphconv = DynamicEdgeConv(nn=convnetwork, aggr=aggr, k=k)\n",
    "        self.skip_link = skip_link\n",
    "        \n",
    "    def forward(self, X, edge_index=None):\n",
    "        H = self.dynamicgraphconv(X)\n",
    "\n",
    "        if self.skip_link:\n",
    "            return torch.hstack((H, X))\n",
    "\n",
    "        return H    \n",
    "\n",
    "\n",
    "class TracksterGraphNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, dropout=0.2, skip_link=False):\n",
    "        super(LCGraphNet, self).__init__()\n",
    "        # particlenet light\n",
    "        \n",
    "        hdim1 = 64\n",
    "        in_dim2 = hdim1 + input_dim if skip_link else hdim1\n",
    "        \n",
    "        hdim2 = 64\n",
    "        in_dim3 = hdim2 + in_dim2 if skip_link else hdim2\n",
    "\n",
    "        hdim3 = 128\n",
    "        # in_dim4 = hdim3 + in_dim3 if skip_link else hdim3\n",
    "\n",
    "        # EdgeConv\n",
    "        self.graphconv1 = EdgeConvBlock(input_dim, hdim1, skip_link=skip_link)\n",
    "        self.graphconv2 = EdgeConvBlock(in_dim2, hdim2, skip_link=skip_link)\n",
    "        \n",
    "        # self.graphconv3 = EdgeConvBlock(in_dim3, hdim3, skip_link=skip_link)\n",
    "        # Edge features from node embeddings for classification\n",
    "        \n",
    "        self.edgenetwork = nn.Sequential(\n",
    "            nn.Linear(in_dim3, hdim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hdim3, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "    def forward(self, X, _edge_index=None):   \n",
    "        \n",
    "        H = self.graphconv1(X)\n",
    "        H = self.graphconv2(H)\n",
    "        # H = self.graphconv3(H)\n",
    "        \n",
    "        return self.edgenetwork(H).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f1e82-74c5-4629-9b20-f05d7662aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script echo skipping\n",
    "\n",
    "model = TracksterGraphNet(input_dim=ds.data.x.shape[1], skip_link=False)\n",
    "epochs = 20\n",
    "\n",
    "# alpha - percentage of negative edges\n",
    "loss_func = FocalLoss(alpha=balance, gamma=2)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_true, train_pred = train_edge_pred(\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        loss_func,\n",
    "        train_dl\n",
    "    )\n",
    "    \n",
    "    train_acc = metrics.balanced_accuracy_score((train_true > 0.5).astype(int), (train_pred > 0.5).astype(int))\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        test_loss, test_true, test_pred = test_edge_pred(model, device, loss_func, test_dl)\n",
    "        test_acc = metrics.balanced_accuracy_score((test_true > 0.5).astype(int), (test_pred > 0.5).astype(int))\n",
    "        print(\n",
    "            f\"Epoch {epoch}:\",\n",
    "            f\"\\ttrain loss:{train_loss:.2f}\\ttrain bacc: {train_acc:.3f}\",\n",
    "            f\"\\t test loss:{test_loss:.2f} \\t test bacc: {test_acc:.3f}\",\n",
    "            file=sys.stderr\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9993b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f\"models/LCGraphNet.64.128.128.ns.{epochs}e-{ds_name}.{ds.RADIUS}.{ds.SCORE_THRESHOLD}.{ds.N_FILES}f.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e14bc7-4d33-485b-9075-348fa0bd284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_curve(model, device, test_dl, step=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve",
   "language": "python",
   "name": "ve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "75d0e37245d408f3d59eb152d126431f02f862b5012558b3df6d65a37ffc466c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
