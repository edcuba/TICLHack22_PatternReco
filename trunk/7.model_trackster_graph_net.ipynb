{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c07744a",
   "metadata": {},
   "source": [
    "##  ParticleNet for trackster-level graph\n",
    "\n",
    "Input:\n",
    "- graph of the full event\n",
    "- edges built between tracksters in a feasible neighborhood \n",
    "    - list of edges\n",
    "- label 1 or 0 for each edge\n",
    "\n",
    "Explored options:\n",
    "- GNN with EdgeConv operators to extract information from the neighborhood\n",
    "    - then predict binary output per edge\n",
    "- DGCNN/ParticleNet with DynamicEdgeConv\n",
    "    - let the network make its own edges in the latent space\n",
    "    - use the original edges as a query after the last conv layer\n",
    "\n",
    "Dimensionality:\n",
    "- Using the batch trick to encode multiple samples at once\n",
    "    - need to reindex edges\n",
    "    - automatically handled by torch-geometric dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "260b3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.nn import EdgeConv, DynamicEdgeConv\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.utils as geo_utils\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from reco.training import train_edge_pred, test_edge_pred\n",
    "from reco.dataset import D_TracksterGraph\n",
    "from reco.loss import FocalLoss\n",
    "\n",
    "ds_name = \"CloseByTwoPion\"\n",
    "\n",
    "data_root = \"data\"\n",
    "raw_dir = f\"/Users/ecuba/data/{ds_name}\"\n",
    "\n",
    "# data_root = \"/mnt/ceph/users/ecuba/processed\"\n",
    "# raw_dir = f\"/mnt/ceph/users/ecuba/{ds_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "581fbd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackstersGraph(graphs=100, nodes=2960, edges=24787, max_distance=1000, graph_features=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = T.Compose([T.NormalizeFeatures()])\n",
    "\n",
    "ds = D_TracksterGraph(\n",
    "    ds_name,\n",
    "    data_root,\n",
    "    raw_dir,\n",
    "    N_FILES=1,\n",
    "    MAX_DISTANCE=1000,\n",
    "    include_graph_features=False,\n",
    "    transform=transform,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00cb5bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train graphs: 90, Test graphs: 10\n"
     ]
    }
   ],
   "source": [
    "ds_size = len(ds)\n",
    "test_set_size = ds_size // 10\n",
    "train_set_size = ds_size - test_set_size\n",
    "train_set, test_set = random_split(ds, [train_set_size, test_set_size])\n",
    "print(f\"Train graphs: {len(train_set)}, Test graphs: {len(test_set)}\")\n",
    "\n",
    "# this is very nice - handles the dimensions automatically\n",
    "train_dl = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c256bd03-3038-4161-9b2e-3de5ef8b0178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset balance: 0.733\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset balance: {float(sum(ds.data.y) / len(ds.data.y)):.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efd04957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "353ee579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParticleNet\n",
    "\n",
    "class EdgeConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, aggr=\"add\", k=8): # skip_link=False,\n",
    "        super(EdgeConvBlock, self).__init__()\n",
    "\n",
    "        convnetwork = nn.Sequential(\n",
    "            nn.Linear(2 * input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.graphconv = EdgeConv(nn=convnetwork, aggr=aggr)\n",
    "        # self.dynamicgraphconv = DynamicEdgeConv(nn=convnetwork, aggr=aggr, k=k)\n",
    "        # self.skip_link = skip_link\n",
    "        \n",
    "    def forward(self, X, edge_index):\n",
    "        \n",
    "        #if edge_index is None:\n",
    "        # H = self.dynamicgraphconv(X)\n",
    "        #else:\n",
    "        H = self.graphconv(X, edge_index)\n",
    "\n",
    "        # if self.skip_link:\n",
    "        #     return torch.hstack((H, X))\n",
    "\n",
    "        return H    \n",
    "\n",
    "\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, aggr='add', dropout=0.2, skip_link=False):\n",
    "        \"\"\"\n",
    "        skip_link might not make so much difference if the edges are fixed\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GraphNet, self).__init__()\n",
    "\n",
    "        hdim1 = 64\n",
    "        in_dim2 = hdim1 # + input_dim if skip_link else hdim1\n",
    "        \n",
    "        hdim2 = 128\n",
    "        in_dim3 = hdim2 # + in_dim2 if skip_link else hdim2\n",
    "\n",
    "        hdim3 = 256\n",
    "        in_dim4 = hdim3 # + in_dim3 if skip_link else hdim3\n",
    "\n",
    "        # EdgeConv\n",
    "        self.graphconv1 = EdgeConvBlock(input_dim, hdim1) #, skip_link=skip_link)\n",
    "        self.graphconv2 = EdgeConvBlock(in_dim2, hdim2) #, skip_link=skip_link)\n",
    "        self.graphconv3 = EdgeConvBlock(in_dim3, hdim3) #, skip_link=skip_link)\n",
    "\n",
    "        # Edge features from node embeddings for classification\n",
    "        self.edgenetwork = nn.Sequential(\n",
    "            nn.Linear(in_dim4, hdim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hdim3, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "    def forward(self, X, edge_index):        \n",
    "        # (prepared_edges, _) = geo_utils.add_self_loops(edge_index)  \n",
    "        undirected_index = geo_utils.to_undirected(edge_index)\n",
    "\n",
    "        H = self.graphconv1(X, undirected_index)\n",
    "        H = self.graphconv2(H, undirected_index)\n",
    "        H = self.graphconv3(H, undirected_index)\n",
    "        \n",
    "        #src, dst = edge_index | torch.cat([H[src], H[dst]], dim=-1)\n",
    "        return self.edgenetwork(H).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b9be07a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch_geometric/data/storage.py:62\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch_geometric/data/storage.py:85\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mask'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m scheduler \u001b[39m=\u001b[39m CosineAnnealingLR(optimizer, epochs, eta_min\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> 14\u001b[0m     train_loss, train_true, train_pred \u001b[39m=\u001b[39m train_edge_pred(\n\u001b[1;32m     15\u001b[0m         model,\n\u001b[1;32m     16\u001b[0m         device,\n\u001b[1;32m     17\u001b[0m         optimizer,\n\u001b[1;32m     18\u001b[0m         loss_func,\n\u001b[1;32m     19\u001b[0m         train_dl\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     train_acc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(train_true, (train_pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))\n\u001b[1;32m     23\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/devel/pattern-reco/reco/training.py:31\u001b[0m, in \u001b[0;36mtrain_edge_pred\u001b[0;34m(model, device, optimizer, loss_func, train_dl)\u001b[0m\n\u001b[1;32m     28\u001b[0m seg_pred \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index)\n\u001b[1;32m     29\u001b[0m y_true \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my\n\u001b[0;32m---> 31\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39;49mmask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     seg_pred \u001b[39m=\u001b[39m seg_pred[data\u001b[39m.\u001b[39mmask]\n\u001b[1;32m     33\u001b[0m     y_true \u001b[39m=\u001b[39m y_true[data\u001b[39m.\u001b[39mmask]\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch_geometric/data/data.py:428\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    423\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    424\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 428\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch_geometric/data/storage.py:64\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'mask'"
     ]
    }
   ],
   "source": [
    "model = GraphNet(input_dim=ds.data.x.shape[1], skip_link=False)\n",
    "epochs = 50\n",
    "\n",
    "# loss_func = F.binary_cross_entropy_with_logits\n",
    "# alpha - percentage of negative edges\n",
    "loss_func = FocalLoss(alpha=0.75, gamma=2)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_true, train_pred = train_edge_pred(\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        loss_func,\n",
    "        train_dl\n",
    "    )\n",
    "    \n",
    "    train_acc = metrics.accuracy_score(train_true, (train_pred > 0.5).astype(int))\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        test_loss, test_true, test_pred = test_edge_pred(model, device, loss_func, test_dl)\n",
    "        test_acc = metrics.accuracy_score(test_true, (test_pred > 0.5).astype(int))\n",
    "        print(\n",
    "            f\"Epoch {epoch}:\",\n",
    "            f\"\\ttrain loss:{train_loss:.2f}\\ttrain acc: {train_acc:.3f}\",\n",
    "            f\"\\t test loss:{test_loss:.2f} \\t test acc: {test_acc:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fdf4fdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m accuracy \u001b[39m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m th \u001b[39min\u001b[39;00m th_values:\n\u001b[0;32m----> 8\u001b[0m     test_loss, test_true, test_pred \u001b[39m=\u001b[39m test_edge_pred(model, device, loss_func, test_dl)\n\u001b[1;32m     10\u001b[0m     pred \u001b[39m=\u001b[39m (test_pred \u001b[39m>\u001b[39m th)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39msum\u001b[39m(pred) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/devel/pattern-reco/reco/training.py:67\u001b[0m, in \u001b[0;36mtest_edge_pred\u001b[0;34m(model, device, loss_func, test_dl, obj_cond)\u001b[0m\n\u001b[1;32m     64\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m     65\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 67\u001b[0m seg_pred \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     69\u001b[0m y_true \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mmask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[41], line 73\u001b[0m, in \u001b[0;36mGraphNet.forward\u001b[0;34m(self, X, edge_index)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X, edge_index):        \n\u001b[1;32m     70\u001b[0m     \u001b[39m# (prepared_edges, _) = geo_utils.add_self_loops(edge_index)  \u001b[39;00m\n\u001b[1;32m     71\u001b[0m     undirected_index \u001b[39m=\u001b[39m geo_utils\u001b[39m.\u001b[39mto_undirected(edge_index)\n\u001b[0;32m---> 73\u001b[0m     H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraphconv1(X, undirected_index)\n\u001b[1;32m     74\u001b[0m     H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraphconv2(H, undirected_index)\n\u001b[1;32m     75\u001b[0m     H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraphconv3(H, undirected_index)\n",
      "File \u001b[0;32m~/devel/pattern-reco/ve/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "th_values = [i / 100. for i in range(1, 99)]\n",
    "precision = []\n",
    "recall = []\n",
    "fbeta = []\n",
    "accuracy = []\n",
    "\n",
    "for th in th_values:\n",
    "    test_loss, test_true, test_pred = test_edge_pred(model, device, loss_func, test_dl)\n",
    "\n",
    "    pred = (test_pred > th).astype(int)\n",
    "\n",
    "    if sum(pred) == 0:\n",
    "        precision.append(0)\n",
    "        recall.append(0)\n",
    "        fbeta.append(0)\n",
    "        accuracy.append(0)\n",
    "    else:\n",
    "        accuracy.append(metrics.accuracy_score(test_true, pred))\n",
    "        precision.append(metrics.precision_score(test_true, pred))\n",
    "        recall.append(metrics.recall_score(test_true, pred))\n",
    "        fbeta.append(metrics.fbeta_score(test_true, pred, beta=1))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(th_values, precision, label=\"precision\")\n",
    "plt.plot(th_values, recall, label=\"recall\")\n",
    "plt.plot(th_values, fbeta, label=\"fbeta\")\n",
    "plt.plot(th_values, accuracy, label=\"accuracy\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "decision_th = th_values[np.argmax(fbeta)]\n",
    "print(f\"Th: {decision_th} | F-score: {max(fbeta):.3f} | accuracy: {accuracy[np.argmax(fbeta)]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcff687",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/DynamicParticleNet_64_128_256_noskip-{epochs}e-CloseByTwoPion_10_10_ngf_{ds.N_FILES}f.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e324e1-d77d-418f-9cbb-8c5f0e8d24f6",
   "metadata": {},
   "source": [
    "## Scoreboard\n",
    "\n",
    "### EdgeConv-based\n",
    "\n",
    "ParticleNet_64_128_256_skip\n",
    "- Best F-score: 0.902\n",
    "- Accuracy: 0.937\n",
    "    \n",
    "ParticleNet_64_128_256_noskip\n",
    "- Best F-score: 0.902\n",
    "- accuracy: 0.937\n",
    "\n",
    "### DynamicEdgeConv\n",
    "\n",
    "The knn search in the highly dimensional space makes the training much slower.\n",
    "\n",
    "DynamicParticleNet_64_128_256_skip\n",
    "- F-score: 0.880\n",
    "- accuracy: 0.922\n",
    "- TH: 0.45\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fee9c84-b14a-4f99-9fe7-3b5264fba82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "from reco.evaluation import graph_model_evaluation\n",
    "\n",
    "file_name = f\"{raw_dir}/new_ntuples_15101852_158.root\"\n",
    "\n",
    "tracksters = uproot.open({file_name: \"ticlNtuplizer/tracksters\"})\n",
    "simtracksters = uproot.open({file_name: \"ticlNtuplizer/simtrackstersSC\"})\n",
    "graphs = uproot.open({file_name: \"ticlNtuplizer/graph\"})\n",
    "associations = uproot.open({file_name: \"ticlNtuplizer/associations\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "471fa906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphNet(input_dim=ds.data.x.shape[1]) #$, skip_link=False)\n",
    "\n",
    "# model.load_state_dict(torch.load(\n",
    "#     \"models/ParticleNet_64_128_256_noskip-100e-CloseByTwoPion_10_10_ngf_500f.pt\",\n",
    "#     map_location=torch.device('cpu')\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f502cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "onnx_filepath = f\"onnx/ParticleNet_64_128_256_noskip-CloseByTwoPion_10_10_ngf_{ds.N_FILES}f.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                          # model to be exported\n",
    "    (ds[0].x, ds[0].edge_index),    # example input (add batch dimension)\n",
    "    onnx_filepath,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['features'],      # the model's input names\n",
    "    output_names=['output'],    # the model's output names\n",
    "    dynamic_axes={              # variable length axes\n",
    "        'features' : {0 : 'batch_size'},    \n",
    "        'output' : {0 : 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a88692-eada-4152-8ef9-e51cda092f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph_model_evaluation(\n",
    "    tracksters,\n",
    "    simtracksters,\n",
    "    associations,\n",
    "    graphs,\n",
    "    model.to(\"cpu\"),\n",
    "    0.5,\n",
    "    max_distance=10,\n",
    "    energy_threshold=10,\n",
    "    max_events=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco.dummy import GraphNaiveDummy\n",
    "\n",
    "result = graph_model_evaluation(\n",
    "    tracksters,\n",
    "    simtracksters,\n",
    "    associations,\n",
    "    graphs,\n",
    "    GraphNaiveDummy(),\n",
    "    0.5,\n",
    "    max_distance=10,\n",
    "    energy_threshold=10,\n",
    "    max_events=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c27b92",
   "metadata": {},
   "source": [
    "## Results interpretation\n",
    "\n",
    "The network is doing a good job in reaching the reconstruction target.\n",
    "Recall is improved while the precision is kept.\n",
    "\n",
    "Network performance:\n",
    "```\n",
    "mean clue3d_to_sim:\tP: 0.96 R: 0.22 F: 0.25\n",
    "mean target_to_sim:\tP: 0.96 R: 0.46 F: 0.51\n",
    "mean reco_to_sim:\tP: 0.96 R: 0.45 F: 0.50\n",
    "```\n",
    "\n",
    "Yet, the dataset is too simple as connecting to all the tracksters in the small neighbourhood is feasible without a significant precision loss.\n",
    "\n",
    "Connecting all tracksters within a small neighborhood:\n",
    "```\n",
    "mean clue3d_to_sim:\tP: 0.96 R: 0.22 F: 0.25\n",
    "mean reco_to_sim:\tP: 0.95 R: 0.48 F: 0.53\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "37c238d9819f69c2c770157eac01081978c120e64661e10d7fd52c4caf977dc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
