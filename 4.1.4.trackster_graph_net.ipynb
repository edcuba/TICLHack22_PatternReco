{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c07744a",
   "metadata": {},
   "source": [
    "# Model: Trackster neighborhood approach\n",
    "\n",
    "Input:\n",
    "- graph of tracksters in the cone neighbourhood.\n",
    "- list of edges\n",
    "- label 1 or 0 for each edge\n",
    "\n",
    "Options:\n",
    "- use EdgeConv operators to extract information from the neighborhood\n",
    "    - then predict binary output per edge\n",
    "- try: use DGCNN to let the network make its own edges in the latent space\n",
    "    - force the original edges in the last conv layer to get the same output?\n",
    "\n",
    "Use the batch trick to encode multiple samples at once (need to reindex edges).\n",
    "- start with batch size 1 to make this easier\n",
    "\n",
    "Using torch_geometric here as it's much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "260b3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.nn import EdgeConv, DynamicEdgeConv\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.utils as geo_utils\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from reco.learn import train_edge_pred, test_edge_pred\n",
    "from reco.dataset import TracksterGraph\n",
    "from reco.loss import FocalLoss\n",
    "\n",
    "ds_name = \"CloseByTwoPion\"\n",
    "\n",
    "# data_root = \"data\"\n",
    "# raw_dir = f\"/Users/ecuba/data/{ds_name}\"\n",
    "\n",
    "data_root = \"/mnt/ceph/users/ecuba/processed\"\n",
    "raw_dir = f\"/mnt/ceph/users/ecuba/{ds_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "581fbd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackstersGraph(graphs=49929, nodes=1406097, edges=5088768, max_distance=10, energy_threshold=10, graph_features=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = T.Compose([T.NormalizeFeatures()])\n",
    "\n",
    "ds = TracksterGraph(\n",
    "    ds_name,\n",
    "    data_root,\n",
    "    raw_dir,\n",
    "    N_FILES=500,\n",
    "    MAX_DISTANCE=10,\n",
    "    ENERGY_THRESHOLD=10,\n",
    "    include_graph_features=False,\n",
    "    transform=transform,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a97f90-41de-480e-8894-52bbd5fc2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a custom scaler so we can reuse it in evaluation\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ds.data.x)\n",
    "ds.x = torch.tensor(scaler.transform(ds.x)).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00cb5bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train graphs: 44937, Test graphs: 4992\n"
     ]
    }
   ],
   "source": [
    "ds_size = len(ds)\n",
    "test_set_size = ds_size // 10\n",
    "train_set_size = ds_size - test_set_size\n",
    "train_set, test_set = random_split(ds, [train_set_size, test_set_size])\n",
    "print(f\"Train graphs: {len(train_set)}, Test graphs: {len(test_set)}\")\n",
    "\n",
    "# this is very nice - handles the dimensions automatically\n",
    "train_dl = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c256bd03-3038-4161-9b2e-3de5ef8b0178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset balance: 0.302\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset balance: {float(sum(ds.data.y) / len(ds.data.y)):.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "efd04957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "353ee579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParticleNet\n",
    "\n",
    "class EdgeConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, aggr=\"add\", skip_link=False, k=16):\n",
    "        super(EdgeConvBlock, self).__init__()\n",
    "\n",
    "        convnetwork = nn.Sequential(\n",
    "            nn.Linear(2 * input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.graphconv = EdgeConv(nn=convnetwork, aggr=aggr)\n",
    "        self.dynamicgraphconv = DynamicEdgeConv(nn=convnetwork, aggr=aggr, k=k)\n",
    "        self.skip_link = skip_link\n",
    "        \n",
    "    def forward(self, X, edge_index=None):\n",
    "        \n",
    "        if edge_index is None:\n",
    "            H = self.dynamicgraphconv(X)\n",
    "        else:\n",
    "            H = self.graphconv(X, edge_index)\n",
    "\n",
    "        if self.skip_link:\n",
    "            return torch.hstack((H, X))\n",
    "\n",
    "        return H\n",
    "\n",
    "\n",
    "\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, aggr='add', dropout=0.2, skip_link=False):\n",
    "        \"\"\"\n",
    "        skip_link might not make so much difference if the edges are fixed\n",
    "        \"\"\"\n",
    "        \n",
    "        super(GraphNet, self).__init__()\n",
    "\n",
    "        hdim1 = 64\n",
    "        in_dim2 = hdim1 + input_dim if skip_link else hdim1\n",
    "        \n",
    "        hdim2 = 128\n",
    "        in_dim3 = hdim2 + in_dim2 if skip_link else hdim2\n",
    "\n",
    "        hdim3 = 256\n",
    "        in_dim4 = hdim3 + in_dim3 if skip_link else hdim3\n",
    "\n",
    "        # EdgeConv\n",
    "        self.graphconv1 = EdgeConvBlock(input_dim, hdim1, skip_link=skip_link)\n",
    "        self.graphconv2 = EdgeConvBlock(in_dim2, hdim2, skip_link=skip_link)\n",
    "        self.graphconv3 = EdgeConvBlock(in_dim3, hdim3, skip_link=skip_link)\n",
    "\n",
    "        # Edge features from node embeddings for classification\n",
    "        self.edgenetwork = nn.Sequential(\n",
    "            nn.Linear(2 * in_dim4, hdim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hdim3, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "            \n",
    "    def forward(self, X, edge_index):        \n",
    "        # (prepared_edges, _) = geo_utils.add_self_loops(edge_index)  \n",
    "        undirected_index = geo_utils.to_undirected(edge_index)\n",
    "\n",
    "        H = self.graphconv1(X, undirected_index)\n",
    "        H = self.graphconv2(H)\n",
    "        H = self.graphconv3(H)\n",
    "        \n",
    "        src, dst = edge_index\n",
    "        return self.edgenetwork(torch.cat([H[src], H[dst]], dim=-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9be07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \ttrain loss:1705.76\ttrain acc: 0.814 \t test loss:78.36 \t test acc: 0.856\n",
      "Epoch 2: \ttrain loss:379.34\ttrain acc: 0.890 \t test loss:31.39 \t test acc: 0.901\n",
      "Epoch 4: \ttrain loss:250.96\ttrain acc: 0.907 \t test loss:22.28 \t test acc: 0.914\n",
      "Epoch 6: \ttrain loss:203.41\ttrain acc: 0.914 \t test loss:18.84 \t test acc: 0.918\n",
      "Epoch 8: \ttrain loss:177.27\ttrain acc: 0.918 \t test loss:16.65 \t test acc: 0.923\n",
      "Epoch 10: \ttrain loss:161.99\ttrain acc: 0.921 \t test loss:14.89 \t test acc: 0.926\n",
      "Epoch 12: \ttrain loss:151.27\ttrain acc: 0.922 \t test loss:14.27 \t test acc: 0.927\n",
      "Epoch 14: \ttrain loss:142.43\ttrain acc: 0.924 \t test loss:13.77 \t test acc: 0.927\n",
      "Epoch 16: \ttrain loss:135.20\ttrain acc: 0.925 \t test loss:13.03 \t test acc: 0.928\n",
      "Epoch 18: \ttrain loss:130.76\ttrain acc: 0.926 \t test loss:13.02 \t test acc: 0.929\n",
      "Epoch 20: \ttrain loss:126.51\ttrain acc: 0.927 \t test loss:12.00 \t test acc: 0.931\n",
      "Epoch 22: \ttrain loss:123.02\ttrain acc: 0.928 \t test loss:12.11 \t test acc: 0.930\n",
      "Epoch 24: \ttrain loss:119.97\ttrain acc: 0.928 \t test loss:11.43 \t test acc: 0.932\n",
      "Epoch 26: \ttrain loss:117.29\ttrain acc: 0.929 \t test loss:12.67 \t test acc: 0.927\n",
      "Epoch 28: \ttrain loss:113.95\ttrain acc: 0.930 \t test loss:11.13 \t test acc: 0.932\n"
     ]
    }
   ],
   "source": [
    "model = GraphNet(input_dim=ds.data.x.shape[1], skip_link=False)\n",
    "epochs = 100\n",
    "\n",
    "# loss_func = F.binary_cross_entropy_with_logits\n",
    "# alpha - percentage of negative edges\n",
    "loss_func = FocalLoss(alpha=0.3, gamma=2)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_true, train_pred = train_edge_pred(\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        loss_func,\n",
    "        train_dl\n",
    "    )\n",
    "    \n",
    "    train_acc = metrics.accuracy_score(train_true, (train_pred > 0.5).astype(int))\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        test_loss, test_true, test_pred = test_edge_pred(model, device, loss_func, test_dl)\n",
    "        test_acc = metrics.accuracy_score(test_true, (test_pred > 0.5).astype(int))\n",
    "        print(\n",
    "            f\"Epoch {epoch}:\",\n",
    "            f\"\\ttrain loss:{train_loss:.2f}\\ttrain acc: {train_acc:.3f}\",\n",
    "            f\"\\t test loss:{test_loss:.2f} \\t test acc: {test_acc:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_values = [i / 100. for i in range(1, 99)]\n",
    "precision = []\n",
    "recall = []\n",
    "fbeta = []\n",
    "accuracy = []\n",
    "\n",
    "for th in th_values:\n",
    "    test_loss, test_true, test_pred = test_edge_pred(model, device, loss_func, test_dl)\n",
    "\n",
    "    pred = (test_pred > th).astype(int)\n",
    "\n",
    "    if sum(pred) == 0:\n",
    "        precision.append(0)\n",
    "        recall.append(0)\n",
    "        fbeta.append(0)\n",
    "        accuracy.append(0)\n",
    "    else:\n",
    "        accuracy.append(metrics.accuracy_score(test_true, pred))\n",
    "        precision.append(metrics.precision_score(test_true, pred))\n",
    "        recall.append(metrics.recall_score(test_true, pred))\n",
    "        fbeta.append(metrics.fbeta_score(test_true, pred, beta=1))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(th_values, precision, label=\"precision\")\n",
    "plt.plot(th_values, recall, label=\"recall\")\n",
    "plt.plot(th_values, fbeta, label=\"fbeta\")\n",
    "plt.plot(th_values, accuracy, label=\"accuracy\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "decision_th = th_values[np.argmax(fbeta)]\n",
    "print(f\"Th: {decision_th} | F-score: {max(fbeta):.3f} | accuracy: {accuracy[np.argmax(fbeta)]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcff687",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/DynamicParticleNet_64_128_256_noskip-{epochs}e-CloseByTwoPion_10_10_ngf_{ds.N_FILES}f.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e324e1-d77d-418f-9cbb-8c5f0e8d24f6",
   "metadata": {},
   "source": [
    "## Scoreboard\n",
    "- ParticleNet_64_128_256_skip\n",
    "    - Best F-score: 0.902\n",
    "    - Accuracy: 0.937\n",
    "    \n",
    " - ParticleNet_64_128_256_noskip\n",
    "     - Best F-score: 0.902\n",
    "     - accuracy: 0.937\n",
    "     \n",
    "     \n",
    " - DynamicParticleNet_64_128_256_noskip (this thing is super slow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c9b21-defa-48ad-a265-ae5d269483ed",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee9c84-b14a-4f99-9fe7-3b5264fba82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "from reco.evaluation import graph_model_evaluation\n",
    "\n",
    "file_name = f\"{raw_dir}/new_ntuples_15101852_455.root\"\n",
    "tracksters = uproot.open({file_name: \"ticlNtuplizer/tracksters\"})\n",
    "simtracksters = uproot.open({file_name: \"ticlNtuplizer/simtrackstersSC\"})\n",
    "graphs = uproot.open({file_name: \"ticlNtuplizer/graph\"})\n",
    "associations = uproot.open({file_name: \"ticlNtuplizer/associations\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a88692-eada-4152-8ef9-e51cda092f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph_model_evaluation(\n",
    "    tracksters,\n",
    "    simtracksters,\n",
    "    associations,\n",
    "    graphs,\n",
    "    model.to(\"cpu\"),\n",
    "    decision_th,\n",
    "    max_distance=10,\n",
    "    energy_threshold=10,\n",
    "    max_events=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve",
   "language": "python",
   "name": "ve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "75d0e37245d408f3d59eb152d126431f02f862b5012558b3df6d65a37ffc466c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
